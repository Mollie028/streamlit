import streamlit as st
import requests
from audio_recorder_streamlit import audio_recorder

# ------------------------
# è¨­å®šèˆ‡å‡è³‡æ–™
# ------------------------
st.set_page_config(page_title="åç‰‡è¾¨è­˜ç³»çµ±", layout="centered")
API_BASE = "https://ocr-whisper-api-production-03e9.up.railway.app"
DUMMY_USERNAME = "testuser"
DUMMY_PASSWORD = "123456"
DUMMY_ROLE = "admin"
DUMMY_TOKEN = "fake-token"

if "current_page" not in st.session_state:
    st.session_state["current_page"] = "login"

# ------------------------
# ç™»å‡ºæŒ‰éˆ•ï¼ˆéç™»å…¥é æ‰é¡¯ç¤ºï¼‰
# ------------------------
if st.session_state.get("access_token") and st.session_state["current_page"] != "login":
    if st.button("ğŸ”“ ç™»å‡º"):
        st.session_state.clear()
        st.session_state["current_page"] = "login"
        st.rerun()

# ------------------------
# ç™»å…¥é é¢
# ------------------------
if st.session_state["current_page"] == "login":
    st.title("ğŸ” ç™»å…¥ç³»çµ±")
    username = st.text_input("å¸³è™Ÿ")
    password = st.text_input("å¯†ç¢¼", type="password")
    if st.button("ç™»å…¥"):
        if username == DUMMY_USERNAME and password == DUMMY_PASSWORD:
            st.session_state["access_token"] = DUMMY_TOKEN
            st.session_state["username"] = DUMMY_USERNAME
            st.session_state["role"] = DUMMY_ROLE
            st.session_state["current_page"] = "home"
            st.rerun()
        else:
            st.error("âŒ å¸³è™Ÿæˆ–å¯†ç¢¼éŒ¯èª¤")

# ------------------------
# é¦–é ï¼šä¾è§’è‰²é¡¯ç¤ºåŠŸèƒ½
# ------------------------
elif st.session_state["current_page"] == "home":
    st.success(f"ğŸ‰ æ­¡è¿ {st.session_state['username']}ï¼ˆ{st.session_state['role']}ï¼‰")

     if st.session_state["role"] == "admin":
        st.info("ğŸ› ï¸ ç®¡ç†å“¡åŠŸèƒ½")
        if st.button("ğŸ“¤ è³‡æ–™åŒ¯å‡º"):
            st.session_state["current_page"] = "export"
            st.rerun()
        if st.button("ğŸ” å¸³è™Ÿç®¡ç†"):
            st.session_state["current_page"] = "accounts"
            st.rerun()
        if st.button("ğŸ—‘ï¸ åç‰‡åˆªé™¤"):
            st.session_state["current_page"] = "delete"
            st.rerun()

    st.info("ğŸ› ï¸ åŠŸèƒ½é¸å–®")
    if st.button("ğŸ“· æ‹ç…§ä¸Šå‚³åç‰‡"):
        st.session_state["current_page"] = "ocr"
        st.rerun()
    if st.button("ğŸ¤ éŒ„éŸ³èªéŸ³å‚™è¨»"):
        st.session_state["current_page"] = "voice"
        st.rerun()
     if st.button("ğŸ” æŸ¥è©¢åç‰‡ç´€éŒ„"):
        st.session_state["current_page"] = "search"
        st.rerun()

# ------------------------
# OCR åç‰‡è¾¨è­˜åŠŸèƒ½é 
# ------------------------
elif st.session_state["current_page"] == "ocr":
    st.header("ğŸ“· åç‰‡è¾¨è­˜ï¼ˆæ”¯æ´å¤šå¼µï¼‰")
    img_files = st.file_uploader("è«‹ä¸Šå‚³åç‰‡åœ–ç‰‡ï¼ˆæ”¯æ´ jpg/pngï¼‰", type=["jpg", "jpeg", "png"], accept_multiple_files=True)

    if img_files:
        for img_file in img_files:
            st.image(img_file, caption=f"é è¦½ï¼š{img_file.name}", width=300)
            with st.spinner(f"ğŸ” OCR è¾¨è­˜ä¸­ï¼š{img_file.name}"):
                try:
                    files = {"file": (img_file.name, img_file.getvalue(), img_file.type)}
                    res = requests.post(f"{API_BASE}/ocr", files=files)
                    res.raise_for_status()
                    ocr_response = res.json()
                    text = ocr_response.get("text", "").strip()
                    record_id = ocr_response.get("id")
                    if not text:
                        st.warning(f"âš ï¸ {img_file.name} æ²’æœ‰è¾¨è­˜å‡ºä»»ä½•æ–‡å­—")
                    else:
                        user_input = st.text_area(f"ğŸ“„ {img_file.name} OCR è¾¨è­˜çµæœï¼ˆå¯ä¿®æ”¹ï¼‰", value=text, height=200)
                        if st.button(f"âœ… ç¢ºèªé€å‡º LLaMA åˆ†æï¼š{img_file.name}", key=img_file.name):
                            with st.spinner("é€²è¡Œè³‡æ–™èƒå–..."):
                                try:
                                    payload = {"text": user_input, "id": record_id}
                                    llama_res = requests.post(f"{API_BASE}/extract", json=payload)
                                    llama_res.raise_for_status()
                                    st.success("âœ… LLaMA æ¡é›†çµæœï¼š")
                                    st.json(llama_res.json())
                                except Exception as e:
                                    st.error(f"âŒ LLaMA åˆ†æå¤±æ•—ï¼š{e}")
                except Exception as e:
                    st.error(f"âŒ OCR ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    st.button("â¬…ï¸ è¿”å›é¦–é ", on_click=lambda: st.session_state.update(current_page="home"))

# ------------------------
# èªéŸ³å‚™è¨»é é¢
# ------------------------
elif st.session_state["current_page"] == "voice":
    st.header("ğŸ¤ èªéŸ³å‚™è¨»éŒ„éŸ³")
    st.info("å»ºè­°èªéŸ³ 3 ç§’ä»¥ä¸Š")

    if "recorded" not in st.session_state:
        st.session_state.recorded = False
    if "audio_data" not in st.session_state:
        st.session_state.audio_data = None
    if "transcript" not in st.session_state:
        st.session_state.transcript = ""
    if "auto_sent" not in st.session_state:
        st.session_state.auto_sent = False

    if not st.session_state.recorded:
        audio = audio_recorder()
        if audio:
            audio_len = len(audio)
            if audio_len < 2000:
                st.error("â›” éŒ„éŸ³æª”ç‚ºç©ºï¼Œè«‹ç¢ºèªéº¥å…‹é¢¨å·²å•Ÿç”¨ã€‚")
                st.stop()
            elif audio_len < 8000:
                st.warning("âš ï¸ éŒ„éŸ³æ™‚é–“å¤ªçŸ­ï¼ˆ<3 ç§’ï¼‰ï¼Œè«‹å†éŒ„ä¹…ä¸€é»ã€‚")
                st.stop()
            elif audio_len > 2_000_000:
                st.warning("âš ï¸ éŒ„éŸ³æ™‚é–“å¤ªé•·ï¼ˆ>30 ç§’ï¼‰ï¼Œè«‹æ§åˆ¶åœ¨ 10ï½30 ç§’å…§ã€‚")
                st.stop()
            else:
                st.session_state.audio_data = audio
                st.session_state.recorded = True
                st.success("âœ… éŒ„éŸ³å®Œæˆï¼Œæ­£åœ¨è‡ªå‹•é€å‡ºè¾¨è­˜...")
    else:
        st.audio(st.session_state.audio_data, format="audio/wav")
        if not st.session_state.auto_sent:
            with st.spinner("ğŸ§  Whisper èªéŸ³è¾¨è­˜ä¸­..."):
                try:
                    files = {"file": ("audio.wav", st.session_state.audio_data, "audio/wav")}
                    res = requests.post(f"{API_BASE}/whisper", files=files)
                    res.raise_for_status()
                    st.session_state.transcript = res.json().get("text", "")
                    st.session_state.auto_sent = True
                    st.success("âœ… Whisper è¾¨è­˜å®Œæˆï¼")
                except Exception as e:
                    st.error(f"âŒ Whisper ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
                    st.stop()

        if st.session_state.transcript:
            st.text_area("ğŸ“ èªéŸ³è¾¨è­˜çµæœ", value=st.session_state.transcript, height=150)

        if st.button("ğŸ” é‡æ–°éŒ„éŸ³"):
            st.session_state.recorded = False
            st.session_state.auto_sent = False
            st.session_state.audio_data = None
            st.session_state.transcript = ""

    st.button("â¬…ï¸ è¿”å›é¦–é ", on_click=lambda: st.session_state.update(current_page="home"))
